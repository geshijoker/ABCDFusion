{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257d20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9589700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import yaml\n",
    "import configparser\n",
    "import copy\n",
    "import math \n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47352e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "# mpl.use('Agg')\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "matplotlib.rcParams['lines.linewidth'] = 1\n",
    "matplotlib.rcParams['lines.markersize'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240d44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6579aec6",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb026661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/geshi/ABCDFusion\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = '../'\n",
    "try: \n",
    "    os.chdir(ROOT_PATH)\n",
    "    sys.path.insert(0, ROOT_PATH)\n",
    "    print(\"Current working directory: {}\".format(os.getcwd()))\n",
    "except Exception:\n",
    "    print(\"Directory: {} is not valid\".format(ROOT_PATH))\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807e7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and parse config \n",
    "config_file = './configs.yaml'\n",
    "with open(config_file, 'r') as infile:\n",
    "    try:\n",
    "        configs = yaml.safe_load(infile)\n",
    "    except yaml.YAMLError as exc:\n",
    "        sys.exit(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d16470",
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary = configs['Auxiliary']\n",
    "DATA_PATH = auxiliary['DATA_PATH']\n",
    "\n",
    "OTHER_DATA = auxiliary['OTHER_DATA'] \n",
    "DTI_DATA = auxiliary['DTI_DATA'] \n",
    "RS_DATA = auxiliary['RS_DATA']\n",
    "OUTCOME = auxiliary['OUTCOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4665193",
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_file = os.path.join(DATA_PATH, DTI_DATA)\n",
    "rs_file = os.path.join(DATA_PATH, RS_DATA)\n",
    "other_file = os.path.join(DATA_PATH, OTHER_DATA)\n",
    "label_file = os.path.join(DATA_PATH, OUTCOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7af0c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abcdfusion\n",
    "from abcdfusion import get_abcd, metrics, models, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f0080c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf08222",
   "metadata": {},
   "source": [
    "# 2. Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c2b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size=0.2\n",
    "batch_size=128\n",
    "num_splits=5\n",
    "num_workers=0\n",
    "num_epochs=10\n",
    "step_size=10\n",
    "lr=0.001\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb5f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dataset, batch_size, num_workers=0, valid_size=0.2, shuffle=True):\n",
    "    # obtain training indices that will be used for validation\n",
    "    num_data = len(dataset)\n",
    "    if shuffle:\n",
    "        indices = list(range(num_data))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_data))\n",
    "    valid_idx, train_idx = indices[:split], indices[split:]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    # load training data in batches\n",
    "    train_loader = DataLoader(dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              sampler=train_sampler,\n",
    "                              num_workers=num_workers)\n",
    "    \n",
    "    # load validation data in batches\n",
    "    valid_loader = DataLoader(dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              sampler=valid_sampler,\n",
    "                              num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00de7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_dataset = get_abcd(dti_file, rs_file, other_file, label_file)\n",
    "train_loader, valid_loader = create_datasets(abcd_dataset, batch_size, num_workers, valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b50adf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dti:  torch.Size([128, 31]) rs fmri:  torch.Size([128, 270]) other data:  torch.Size([128, 7]) label:  torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "dti, rs, other, y = next(iter(valid_loader))\n",
    "print('dti: ', dti.shape, 'rs fmri: ', rs.shape, 'other data: ', other.shape, 'label: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d565a2",
   "metadata": {},
   "source": [
    "# 3. Define Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232aa502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, num_classes, criterion, optimizer, scheduler, device):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0\n",
    "    epoch_ce = 0.0\n",
    "    epoch_iou = 0.0\n",
    "    epoch_dice = 0.0\n",
    "    count = 0\n",
    "\n",
    "    piter = tqdm(dataloader, desc='Batch', unit='batch', position=1, leave=False)\n",
    "    for inputs, seg_masks in piter:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "            # transfer label to device\n",
    "        targets = target.to(device)\n",
    "        seg_masks = seg_masks.to(device)\n",
    "        _, targets = torch.max(seg_masks, 1)\n",
    "\n",
    "        batch_size = inputs.size(0)\n",
    "        nxt_count = count+batch_size\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, seg_masks)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        epoch_loss = loss.item() * batch_size/nxt_count + epoch_loss * count/nxt_count\n",
    "        epoch_acc = ((preds == targets).sum()/np.prod(preds.size())).item() * batch_size/nxt_count + epoch_acc * count/nxt_count\n",
    "\n",
    "        count = nxt_count\n",
    "        piter.set_postfix(accuracy=100. * epoch_acc)\n",
    "\n",
    "    epoch_acc *= 100.\n",
    "    scheduler.step()\n",
    "    train_stats = {\n",
    "        'train_loss': epoch_loss,\n",
    "        'train_acc': epoch_acc,\n",
    "    }\n",
    "    \n",
    "    return model, epoch_loss, epoch_acc, train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1d6996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, num_classes, device):\n",
    "    since = time.time()\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    \n",
    "    corrects = 0\n",
    "    count = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    with torch.no_grad():\n",
    "        piter = tqdm(dataloader, unit='batch')\n",
    "        for inputs, seg_masks in piter:\n",
    "            piter.set_description(f\"Test \")\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            _, targets = torch.max(seg_masks, 1)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            batch_size = inputs.size(0)\n",
    "            count += batch_size\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            corrects += torch.sum(preds == targets.data)\n",
    "            pos_corrects += torch.sum(preds[] == targets.data)\n",
    "\n",
    "            acc = corrects.double().item() / count\n",
    "            piter.set_postfix(accuracy=100. * acc)\n",
    "\n",
    "\n",
    "    acc = corrects.double().item() / count\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Testing complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s, Test Acc: {100. * acc}, Test Iou: {mean_IOU}')\n",
    "    \n",
    "    test_stats = {\n",
    "        \"test_acc\": 100. * acc,\n",
    "    }\n",
    "\n",
    "    return cl_wise_iou, test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d82d1bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceac547",
   "metadata": {},
   "source": [
    "# 4. DTI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ee24d0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 31)\n",
    "dti_model = models.BinaryMLP(31, [32, 64, 32], p=0.2)\n",
    "out = dti_model(x)\n",
    "print(out.shape)\n",
    "dti_model = dti_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "97feb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor([0.05, 0.95])\n",
    "criterion = metrics.WeightedBCELoss(weights, reduction='mean')# metrics.FocalLoss(gamma=1, weights=weights) # nn.BCELoss() # nn.BCEWithLogitsLoss()\n",
    "# criterion = metrics.FocalLoss(gamma=1, weights=weights)\n",
    "optimizer = optim.Adam(dti_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dd4763f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7a59975eb54b30a643f1ce2a8b392c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/200 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "dti_model.train()\n",
    "pbar = trange(200, desc='Epoch', unit='epoch', initial=0, position=0)\n",
    "for epoch in pbar:  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for inputs, _, _, labels in piter:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.view(-1).long().to(device)\n",
    "        labels = F.one_hot(labels, num_classes=2).float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = dti_model(inputs)\n",
    "        # probs = F.softmax(outputs)\n",
    "        probs = F.sigmoid(outputs)\n",
    "        \n",
    "        loss = criterion(probs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    pbar.set_postfix(loss = running_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "54812e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Validation\n",
      "accuracy:  98.62, pos accuracy:  99.64, neg accuracy:  100.00\n"
     ]
    }
   ],
   "source": [
    "dti_model.eval()\n",
    "with torch.no_grad():\n",
    "    corrects = 0\n",
    "    pos_corrects = 0\n",
    "    neg_corrects = 0\n",
    "    \n",
    "    count = 0\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, _, _, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = dti_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1, keepdim=True)\n",
    "\n",
    "        # statistics\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "        pos_corrects += torch.sum(preds[labels==1] == labels[labels==1].data)\n",
    "        neg_corrects += torch.sum(preds[labels==0] == labels[labels==0].data)\n",
    "        \n",
    "        count += batch_size\n",
    "        pos_count += (labels.data==1).sum()\n",
    "        neg_count += (labels.data==0).sum()\n",
    "\n",
    "    acc = corrects.double().item() / count\n",
    "    pos_acc = pos_corrects.double().item() / pos_count\n",
    "    neg_acc = neg_corrects.double().item() / neg_count\n",
    "\n",
    "print('Finished Training Validation')\n",
    "print(f'accuracy: {acc*100. : .2f}, pos accuracy: {pos_acc*100. : .2f}, neg accuracy: {neg_acc*100. : .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "76eab0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Validation\n",
      "accuracy:  75.00, pos accuracy:  7.81, neg accuracy:  92.00\n"
     ]
    }
   ],
   "source": [
    "dti_model.eval()\n",
    "with torch.no_grad():\n",
    "    corrects = 0\n",
    "    pos_corrects = 0\n",
    "    neg_corrects = 0\n",
    "    \n",
    "    count = 0\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    for i, data in enumerate(valid_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, _, _, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = dti_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1, keepdim=True)\n",
    "\n",
    "        # statistics\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "        pos_corrects += torch.sum(preds[labels==1] == labels[labels==1].data)\n",
    "        neg_corrects += torch.sum(preds[labels==0] == labels[labels==0].data)\n",
    "        \n",
    "        count += batch_size\n",
    "        pos_count += (labels.data==1).sum()\n",
    "        neg_count += (labels.data==0).sum()\n",
    "\n",
    "    acc = corrects.double().item() / count\n",
    "    pos_acc = pos_corrects.double().item() / pos_count\n",
    "    neg_acc = neg_corrects.double().item() / neg_count\n",
    "\n",
    "print('Finished Training Validation')\n",
    "print(f'accuracy: {acc*100. : .2f}, pos accuracy: {pos_acc*100. : .2f}, neg accuracy: {neg_acc*100. : .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab494d",
   "metadata": {},
   "source": [
    "# 5. rs fMRI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "68b2e45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 270)\n",
    "rs_model = models.BinaryMLP(270, [270, 270, 40], p=0.2, hidden_dim=300)\n",
    "out = rs_model(x)\n",
    "print(out.shape)\n",
    "rs_model = rs_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "31eea0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor([0.05, 0.95])\n",
    "criterion = metrics.WeightedBCELoss(weights, reduction='mean')# metrics.FocalLoss(gamma=1, weights=weights) # nn.BCELoss() # nn.BCEWithLogitsLoss()\n",
    "# criterion = metrics.FocalLoss(gamma=1, weights=weights)\n",
    "optimizer = optim.Adam(rs_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "15663654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433781f44fa941a586db883ab4fc765f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/200 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "rs_model.train()\n",
    "pbar = trange(200, desc='Epoch', unit='epoch', initial=0, position=0)\n",
    "for epoch in pbar:  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for _, inputs, _, labels in piter:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.view(-1).long().to(device)\n",
    "        labels = F.one_hot(labels, num_classes=2).float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = rs_model(inputs)\n",
    "        # probs = F.softmax(outputs)\n",
    "        probs = F.sigmoid(outputs)\n",
    "        \n",
    "        loss = criterion(probs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    pbar.set_postfix(loss = running_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "66c48eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Validation\n",
      "accuracy:  98.66, pos accuracy:  100.00, neg accuracy:  100.00\n"
     ]
    }
   ],
   "source": [
    "rs_model.eval()\n",
    "with torch.no_grad():\n",
    "    corrects = 0\n",
    "    pos_corrects = 0\n",
    "    neg_corrects = 0\n",
    "    \n",
    "    count = 0\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        _, inputs, _, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = rs_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1, keepdim=True)\n",
    "\n",
    "        # statistics\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "        pos_corrects += torch.sum(preds[labels==1] == labels[labels==1].data)\n",
    "        neg_corrects += torch.sum(preds[labels==0] == labels[labels==0].data)\n",
    "        \n",
    "        count += batch_size\n",
    "        pos_count += (labels.data==1).sum()\n",
    "        neg_count += (labels.data==0).sum()\n",
    "\n",
    "    acc = corrects.double().item() / count\n",
    "    pos_acc = pos_corrects.double().item() / pos_count\n",
    "    neg_acc = neg_corrects.double().item() / neg_count\n",
    "\n",
    "print('Finished Training Validation')\n",
    "print(f'accuracy: {acc*100. : .2f}, pos accuracy: {pos_acc*100. : .2f}, neg accuracy: {neg_acc*100. : .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b16ef541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Validation\n",
      "accuracy:  78.79, pos accuracy:  0.00, neg accuracy:  97.38, positive predictions: 19\n"
     ]
    }
   ],
   "source": [
    "rs_model.eval()\n",
    "with torch.no_grad():\n",
    "    corrects = 0\n",
    "    pos_corrects = 0\n",
    "    neg_corrects = 0\n",
    "    pos_preds = 0\n",
    "    \n",
    "    count = 0\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    for i, data in enumerate(valid_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        _, inputs, _, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = rs_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1, keepdim=True)\n",
    "\n",
    "        # statistics\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "        pos_corrects += torch.sum(preds[labels==1] == labels[labels==1].data)\n",
    "        neg_corrects += torch.sum(preds[labels==0] == labels[labels==0].data)\n",
    "        \n",
    "        count += batch_size\n",
    "        pos_count += (labels.data==1).sum()\n",
    "        neg_count += (labels.data==0).sum()\n",
    "        pos_preds += (preds.data==1).sum()\n",
    "\n",
    "    acc = corrects.double().item() / count\n",
    "    pos_acc = pos_corrects.double().item() / pos_count\n",
    "    neg_acc = neg_corrects.double().item() / neg_count\n",
    "\n",
    "print('Finished Training Validation')\n",
    "print(f'accuracy: {acc*100. : .2f}, pos accuracy: {pos_acc*100. : .2f}, neg accuracy: {neg_acc*100. : .2f}, positive predictions: {pos_preds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee18f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
